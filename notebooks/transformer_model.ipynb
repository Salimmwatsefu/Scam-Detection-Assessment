{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sj/code/iwazolab/bongo_scam_detection/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data sample:\n",
      "  Category                                        cleaned_sms\n",
      "0    trust                   nipigie baada saa moja tafadhali\n",
      "1     scam  naomba unitumie iyo hela kwenye namba airtel j...\n",
      "2     scam  karibu freemason utimize ndoto biashara kilimo...\n",
      "3    trust               watoto wanapenda zawadi ulizowaletea\n",
      "4     scam  iyo pesa itume kwenye namba jina italeta magom...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load preprocessed data\n",
    "data = pd.read_csv('../data/processed_bongo_scam.csv')\n",
    "print(\"Preprocessed data sample:\")\n",
    "print(data[['Category', 'cleaned_sms']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 361, Test samples: 91\n"
     ]
    }
   ],
   "source": [
    "# Use a 10% subset for faster training\n",
    "data_subset = data.sample(frac=0.3, random_state=42)\n",
    "\n",
    "# Split data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data_subset['cleaned_sms'].tolist(),\n",
    "    data_subset['Category'].map({'trust': 0, 'scam': 1}).tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Training samples: {len(train_texts)}, Test samples: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AfroXLMR loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('Davlan/afro-xlmr-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('Davlan/afro-xlmr-base', num_labels=2)\n",
    "print(\"AfroXLMR loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize with dynamic padding (max_length=50)\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding='longest', truncation=True, max_length=50, return_tensors='pt')\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "test_encodings = tokenize_function(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch dataset\n",
    "class SwahiliDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SwahiliDataset(train_encodings, train_labels)\n",
    "test_dataset = SwahiliDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../results',\n",
    "    num_train_epochs=1,        \n",
    "    per_device_train_batch_size=8, \n",
    "    per_device_eval_batch_size=8,   \n",
    "    eval_strategy='no',        \n",
    "    save_strategy='no',        \n",
    "    logging_steps=5,         \n",
    "    logging_dir='../logs',\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    return {'f1': f1}\n",
    "print(\"Training setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/46 44:29 < 37:04, 0.01 it/s, Epoch 0.54/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.700100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.372400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation completed. F1-Score: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Generating confusion matrix...\")\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.argmax(-1)\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['trust', 'scam'], yticklabels=['trust', 'scam'])\n",
    "plt.title('Confusion Matrix - AfroXLMR (Full Dataset)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('../reports/visualizations/transformer_confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
